/**
 * SENTINEL SYSTEM - ULTIMATE AUTONOMOUS INTELLIGENCE
 * 
 * ZERO MANUAL INTERVENTION. EVER.
 * 
 * This system:
 * - Watches EVERYTHING 24/7
 * - Detects problems BEFORE they escalate
 * - Takes action AUTOMATICALLY
 * - DMs warnings to users AUTOMATICALLY
 * - Investigates suspicious users AUTOMATICALLY
 * - Bans threats AUTOMATICALLY
 * - Reviews appeals AUTOMATICALLY
 * - Sends you daily reports so you wake up informed
 * - Learns and gets smarter over time
 * 
 * You do NOTHING. The bot handles EVERYTHING.
 */

const { EmbedBuilder, AuditLogEvent } = require('discord.js');

class SentinelSystem {
  constructor(pool, anthropic, client) {
    this.pool = pool;
    this.anthropic = anthropic;
    this.client = client;
    
    // Real-time tracking
    this.messageBuffer = new Map();
    this.userProfiles = new Map();
    this.activeThreats = new Set();
    this.recentJoins = [];
    
    // Learning data
    this.falsePositives = [];
    this.confirmedThreats = [];
  }

  async initialize() {
    await this.initDatabase();
    this.startAllSystems();
    
    console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ğŸ›¡ï¸ SENTINEL SYSTEM ACTIVATED ğŸ›¡ï¸                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  âœ“ Real-time message analysis                             â•‘
â•‘  âœ“ Automatic threat detection                             â•‘
â•‘  âœ“ Auto-warn via DM                                       â•‘
â•‘  âœ“ Auto-mute/kick/ban                                     â•‘
â•‘  âœ“ Auto-investigation of suspicious users                 â•‘
â•‘  âœ“ Auto-appeal processing                                 â•‘
â•‘  âœ“ Daily reports to mod channel                           â•‘
â•‘  âœ“ Raid protection                                        â•‘
â•‘  âœ“ New account monitoring                                 â•‘
â•‘  âœ“ Pattern learning                                       â•‘
â•‘                                                           â•‘
â•‘  YOU DO NOTHING. I HANDLE EVERYTHING.                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    `);
  }

  async initDatabase() {
    await this.pool.query(`
      -- User profiles with full tracking
      CREATE TABLE IF NOT EXISTS sentinel_profiles (
        user_id VARCHAR(32),
        guild_id VARCHAR(32),
        
        -- Activity metrics
        total_messages INT DEFAULT 0,
        total_deletions INT DEFAULT 0,
        messages_today INT DEFAULT 0,
        
        -- Behavior scores (0-100)
        trust_score INT DEFAULT 50,
        risk_score INT DEFAULT 0,
        toxicity_score INT DEFAULT 0,
        
        -- Incident tracking
        warnings_received INT DEFAULT 0,
        mutes_received INT DEFAULT 0,
        kicks_received INT DEFAULT 0,
        bans_received INT DEFAULT 0,
        
        -- Status
        status VARCHAR(16) DEFAULT 'normal',
        under_investigation BOOLEAN DEFAULT FALSE,
        is_threat BOOLEAN DEFAULT FALSE,
        
        -- Timestamps
        first_seen TIMESTAMP DEFAULT NOW(),
        last_active TIMESTAMP DEFAULT NOW(),
        last_warning TIMESTAMP,
        last_investigation TIMESTAMP,
        
        PRIMARY KEY(user_id, guild_id)
      );

      -- All automated actions
      CREATE TABLE IF NOT EXISTS sentinel_actions (
        id SERIAL PRIMARY KEY,
        user_id VARCHAR(32),
        guild_id VARCHAR(32),
        action VARCHAR(32),
        reason TEXT,
        details JSONB,
        dm_sent BOOLEAN DEFAULT FALSE,
        dm_content TEXT,
        confidence FLOAT,
        created_at TIMESTAMP DEFAULT NOW()
      );

      -- Investigation records
      CREATE TABLE IF NOT EXISTS sentinel_investigations (
        id SERIAL PRIMARY KEY,
        user_id VARCHAR(32),
        guild_id VARCHAR(32),
        trigger_reason TEXT,
        evidence JSONB,
        ai_analysis TEXT,
        risk_assessment VARCHAR(16),
        action_taken VARCHAR(32),
        created_at TIMESTAMP DEFAULT NOW()
      );

      -- Appeals (auto-processed)
      CREATE TABLE IF NOT EXISTS sentinel_appeals (
        id SERIAL PRIMARY KEY,
        appeal_id VARCHAR(32) UNIQUE,
        user_id VARCHAR(32),
        guild_id VARCHAR(32),
        original_action VARCHAR(32),
        user_message TEXT,
        ai_review TEXT,
        decision VARCHAR(16),
        decision_reason TEXT,
        executed BOOLEAN DEFAULT FALSE,
        created_at TIMESTAMP DEFAULT NOW()
      );

      -- Daily reports
      CREATE TABLE IF NOT EXISTS sentinel_reports (
        id SERIAL PRIMARY KEY,
        guild_id VARCHAR(32),
        report_date DATE,
        stats JSONB,
        incidents JSONB,
        high_risk_users JSONB,
        ai_summary TEXT,
        UNIQUE(guild_id, report_date)
      );

      -- Message log with sentiment
      CREATE TABLE IF NOT EXISTS sentinel_messages (
        id SERIAL PRIMARY KEY,
        message_id VARCHAR(32),
        user_id VARCHAR(32),
        guild_id VARCHAR(32),
        channel_id VARCHAR(32),
        content TEXT,
        sentiment FLOAT,
        toxicity FLOAT,
        deleted BOOLEAN DEFAULT FALSE,
        edited BOOLEAN DEFAULT FALSE,
        flagged BOOLEAN DEFAULT FALSE,
        flag_reason TEXT,
        created_at TIMESTAMP DEFAULT NOW()
      );
      CREATE INDEX IF NOT EXISTS idx_sentinel_msg_user ON sentinel_messages(user_id, guild_id);
      CREATE INDEX IF NOT EXISTS idx_sentinel_msg_time ON sentinel_messages(created_at);
    `);
  }

  startAllSystems() {
    // Anomaly detection every 30 seconds
    setInterval(() => this.runAnomalyDetection(), 30000);
    
    // Risk score updates every 2 minutes
    setInterval(() => this.updateAllRiskScores(), 120000);
    
    // Auto-investigation queue every minute
    setInterval(() => this.processInvestigationQueue(), 60000);
    
    // Daily report at 6 AM UTC
    this.scheduleDailyReport();
    
    // Cleanup old data hourly
    setInterval(() => this.cleanup(), 3600000);
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // MAIN MESSAGE PROCESSOR - Called for EVERY message
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  async processMessage(message) {
    if (!message.guild || message.author.bot) return null;
    
    const userId = message.author.id;
    const guildId = message.guild.id;
    const content = message.content;
    
    // 1. LOG THE MESSAGE
    const analysis = await this.analyzeContent(content);
    await this.logMessage(message, analysis);
    
    // 2. UPDATE USER PROFILE
    await this.updateProfile(userId, guildId, analysis);
    
    // 3. INSTANT THREAT CHECK
    const threat = this.detectInstantThreat(content);
    if (threat) {
      await this.handleThreat(message, threat);
      return { handled: true, action: threat.action };
    }
    
    // 4. SPAM CHECK
    const spam = this.detectSpam(message);
    if (spam) {
      await this.handleSpam(message, spam);
      return { handled: true, action: 'spam' };
    }
    
    // 5. TOXICITY CHECK
    if (analysis.toxicity > 0.7) {
      await this.handleToxicity(message, analysis);
      return { handled: true, action: 'toxicity' };
    }
    
    // 6. CHECK IF USER NEEDS INVESTIGATION
    const profile = await this.getProfile(userId, guildId);
    if (profile.risk_score > 60 && !profile.under_investigation) {
      this.queueInvestigation(userId, guildId, 'High risk score detected');
    }
    
    return null;
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // CONTENT ANALYSIS
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  async analyzeContent(content) {
    if (!content || content.length < 2) {
      return { sentiment: 0, toxicity: 0, flags: [] };
    }
    
    const flags = [];
    let toxicity = 0;
    
    // Instant high-toxicity patterns
    const toxicPatterns = [
      { pattern: /\b(kys|kill\s*yourself|neck\s*yourself)\b/i, score: 1.0, flag: 'self-harm encouragement' },
      { pattern: /\bn[i1]gg[e3]r\b/i, score: 0.95, flag: 'racial slur' },
      { pattern: /\bf[a4]gg[o0]t\b/i, score: 0.9, flag: 'homophobic slur' },
      { pattern: /\br[e3]t[a4]rd\b/i, score: 0.85, flag: 'ableist slur' },
      { pattern: /\b(kill|murder|shoot)\s*(you|him|her|them)\b/i, score: 0.9, flag: 'threat' },
      { pattern: /\bfuck\s*(you|off)\b/i, score: 0.6, flag: 'hostile' },
      { pattern: /\b(idiot|stupid|dumb|moron)\b/i, score: 0.4, flag: 'insult' }
    ];
    
    for (const p of toxicPatterns) {
      if (p.pattern.test(content)) {
        toxicity = Math.max(toxicity, p.score);
        flags.push(p.flag);
      }
    }
    
    // Simple sentiment (-1 to 1)
    let sentiment = 0;
    const positive = (content.match(/\b(thanks|thank|love|great|awesome|nice|good|amazing|lol|lmao|haha)\b/gi) || []).length;
    const negative = (content.match(/\b(hate|sucks|bad|terrible|awful|annoying|stupid|dumb)\b/gi) || []).length;
    sentiment = (positive - negative) / Math.max(positive + negative, 1);
    
    return { sentiment, toxicity, flags };
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // THREAT DETECTION - Instant action required
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  detectInstantThreat(content) {
    const threats = [
      // SCAMS - Instant ban
      { pattern: /free\s*nitro/i, action: 'ban', reason: 'Nitro scam', confidence: 0.95 },
      { pattern: /discord\.gift(?!s)/i, action: 'ban', reason: 'Fake gift link', confidence: 0.95 },
      { pattern: /discordapp\.com\/gifts/i, action: 'ban', reason: 'Phishing link', confidence: 0.95 },
      { pattern: /steamnity|steamcommunity\.(ru|co)/i, action: 'ban', reason: 'Fake Steam link', confidence: 0.95 },
      { pattern: /claim.*prize|won.*giveaway/i, action: 'ban', reason: 'Prize scam', confidence: 0.9 },
      { pattern: /verify.*wallet|connect.*wallet|airdrop/i, action: 'ban', reason: 'Crypto scam', confidence: 0.9 },
      { pattern: /@everyone.*https?:|@here.*https?:/i, action: 'ban', reason: 'Mass ping scam', confidence: 0.95 },
      
      // SEVERE VIOLATIONS - Instant mute + investigation
      { pattern: /\b(kys|kill\s*yourself)\b/i, action: 'ban', reason: 'Encouraging self-harm', confidence: 0.95 },
      { pattern: /i('ll| will|'m going to)\s*(kill|murder|shoot)\s*(you|him|her)/i, action: 'mute', reason: 'Death threat', confidence: 0.85, investigate: true }
    ];
    
    for (const t of threats) {
      if (t.pattern.test(content)) {
        return t;
      }
    }
    
    return null;
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // SPAM DETECTION
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  detectSpam(message) {
    const userId = message.author.id;
    const content = message.content.toLowerCase();
    const now = Date.now();
    
    // Track messages
    if (!this.messageBuffer.has(userId)) {
      this.messageBuffer.set(userId, []);
    }
    const buffer = this.messageBuffer.get(userId);
    buffer.push({ content, time: now });
    
    // Keep last 2 minutes
    const recent = buffer.filter(m => now - m.time < 120000);
    this.messageBuffer.set(userId, recent);
    
    // Check patterns
    const lastMinute = recent.filter(m => now - m.time < 60000);
    
    // Too many messages
    if (lastMinute.length > 10) {
      return { type: 'flood', count: lastMinute.length };
    }
    
    // Duplicate messages
    const duplicates = lastMinute.filter(m => m.content === content);
    if (duplicates.length >= 3) {
      return { type: 'duplicate', count: duplicates.length };
    }
    
    // Excessive mentions
    if (message.mentions.users.size > 5) {
      return { type: 'mentions', count: message.mentions.users.size };
    }
    
    // Excessive emojis
    const emojiCount = (content.match(/[\u{1F300}-\u{1F9FF}]/gu) || []).length;
    if (emojiCount > 15) {
      return { type: 'emoji', count: emojiCount };
    }
    
    // ALL CAPS
    if (content.length > 20) {
      const upper = (content.match(/[A-Z]/g) || []).length;
      const letters = (content.match(/[a-zA-Z]/g) || []).length;
      if (letters > 0 && upper / letters > 0.7) {
        return { type: 'caps' };
      }
    }
    
    return null;
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ACTION HANDLERS
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  async handleThreat(message, threat) {
    const member = message.member;
    const guild = message.guild;
    
    // Delete message
    await message.delete().catch(() => {});
    
    // Get progressive punishment
    const profile = await this.getProfile(member.id, guild.id);
    
    // Execute action
    if (threat.action === 'ban') {
      await this.executeBan(member, guild, threat.reason, threat.confidence);
    } else if (threat.action === 'mute') {
      const duration = this.getMuteDuration(profile);
      await this.executeMute(member, guild, threat.reason, duration, threat.confidence);
    }
    
    // Queue investigation if needed
    if (threat.investigate) {
      this.queueInvestigation(member.id, guild.id, threat.reason);
    }
  }

  async handleSpam(message, spam) {
    const member = message.member;
    const guild = message.guild;
    
    // Delete message
    await message.delete().catch(() => {});
    
    const profile = await this.getProfile(member.id, guild.id);
    const reason = `Spam detected: ${spam.type}${spam.count ? ` (${spam.count})` : ''}`;
    
    // First offense = warning, repeat = mute
    if (profile.warnings_received < 2) {
      await this.executeWarning(member, guild, reason);
    } else {
      const duration = this.getMuteDuration(profile);
      await this.executeMute(member, guild, reason, duration, 0.85);
    }
  }

  async handleToxicity(message, analysis) {
    const member = message.member;
    const guild = message.guild;
    
    // Delete message
    await message.delete().catch(() => {});
    
    const profile = await this.getProfile(member.id, guild.id);
    const reason = `Toxic content: ${analysis.flags.join(', ')}`;
    
    if (analysis.toxicity > 0.9) {
      // Severe - mute immediately
      const duration = this.getMuteDuration(profile);
      await this.executeMute(member, guild, reason, duration, analysis.toxicity);
    } else {
      // Warning first
      await this.executeWarning(member, guild, reason);
    }
    
    // Update toxicity score
    await this.pool.query(`
      UPDATE sentinel_profiles 
      SET toxicity_score = LEAST(100, toxicity_score + $3)
      WHERE user_id = $1 AND guild_id = $2
    `, [member.id, guild.id, Math.round(analysis.toxicity * 20)]);
  }

  getMuteDuration(profile) {
    const mutes = profile.mutes_received || 0;
    const durations = [5, 15, 60, 360, 1440]; // 5min, 15min, 1hr, 6hr, 24hr
    return durations[Math.min(mutes, durations.length - 1)];
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // EXECUTE ACTIONS - All send DMs automatically
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  async executeWarning(member, guild, reason) {
    // Update profile
    await this.pool.query(`
      UPDATE sentinel_profiles 
      SET warnings_received = warnings_received + 1, last_warning = NOW(), risk_score = LEAST(100, risk_score + 10)
      WHERE user_id = $1 AND guild_id = $2
    `, [member.id, guild.id]);
    
    // DM the user
    const embed = new EmbedBuilder()
      .setTitle('âš ï¸ Warning')
      .setDescription(`You've received an automated warning in **${guild.name}**`)
      .addFields(
        { name: 'Reason', value: reason },
        { name: 'What This Means', value: 'This is a warning. Continued violations will result in automatic mutes, kicks, or bans.' },
        { name: 'Your Status', value: 'Your behavior is being monitored. Please follow the server rules.' }
      )
      .setColor(0xFFAA00)
      .setFooter({ text: 'Automated moderation â€¢ No reply needed' })
      .setTimestamp();
    
    const dmSent = await member.send({ embeds: [embed] }).then(() => true).catch(() => false);
    
    // Log action
    await this.logAction(member.id, guild.id, 'warning', reason, 0.8, dmSent, embed.data.description);
    
    // Log to mod channel (silent, no ping)
    await this.logToMods(guild, 'warning', member, reason, null, 0.8);
  }

  async executeMute(member, guild, reason, durationMinutes, confidence) {
    // Update profile
    await this.pool.query(`
      UPDATE sentinel_profiles 
      SET mutes_received = mutes_received + 1, risk_score = LEAST(100, risk_score + 20)
      WHERE user_id = $1 AND guild_id = $2
    `, [member.id, guild.id]);
    
    // Apply timeout
    await member.timeout(durationMinutes * 60 * 1000, `[AUTO] ${reason}`).catch(console.error);
    
    // DM the user
    const embed = new EmbedBuilder()
      .setTitle('ğŸ”‡ Muted')
      .setDescription(`You've been automatically muted in **${guild.name}**`)
      .addFields(
        { name: 'Reason', value: reason },
        { name: 'Duration', value: `${durationMinutes} minutes` },
        { name: 'Appeal', value: 'If you believe this was a mistake, reply with "appeal" followed by your explanation. An AI will review your case.' }
      )
      .setColor(0xFF8C00)
      .setFooter({ text: 'Automated moderation' })
      .setTimestamp();
    
    const dmSent = await member.send({ embeds: [embed] }).then(() => true).catch(() => false);
    
    await this.logAction(member.id, guild.id, 'mute', reason, confidence, dmSent);
    await this.logToMods(guild, 'mute', member, reason, `${durationMinutes}min`, confidence);
    
    // Check if should escalate to investigation
    const profile = await this.getProfile(member.id, guild.id);
    if (profile.mutes_received >= 3) {
      this.queueInvestigation(member.id, guild.id, 'Multiple mutes received');
    }
  }

  async executeKick(member, guild, reason, confidence) {
    // Update profile
    await this.pool.query(`
      UPDATE sentinel_profiles 
      SET kicks_received = kicks_received + 1, risk_score = LEAST(100, risk_score + 30)
      WHERE user_id = $1 AND guild_id = $2
    `, [member.id, guild.id]);
    
    // DM before kick
    const embed = new EmbedBuilder()
      .setTitle('ğŸ‘¢ Kicked')
      .setDescription(`You've been automatically kicked from **${guild.name}**`)
      .addFields(
        { name: 'Reason', value: reason },
        { name: 'Rejoin', value: 'You may rejoin the server, but continued violations will result in a permanent ban.' },
        { name: 'Appeal', value: 'Reply with "appeal" if you believe this was a mistake.' }
      )
      .setColor(0xFF4500)
      .setTimestamp();
    
    await member.send({ embeds: [embed] }).catch(() => {});
    await member.kick(`[AUTO] ${reason}`).catch(console.error);
    
    await this.logAction(member.id, guild.id, 'kick', reason, confidence, true);
    await this.logToMods(guild, 'kick', member, reason, null, confidence);
  }

  async executeBan(member, guild, reason, confidence) {
    // Update profile
    await this.pool.query(`
      UPDATE sentinel_profiles 
      SET bans_received = bans_received + 1, is_threat = TRUE, risk_score = 100
      WHERE user_id = $1 AND guild_id = $2
    `, [member.id, guild.id]);
    
    // DM before ban
    const embed = new EmbedBuilder()
      .setTitle('ğŸ”¨ Banned')
      .setDescription(`You've been automatically banned from **${guild.name}**`)
      .addFields(
        { name: 'Reason', value: reason },
        { name: 'Appeal', value: 'Reply with "appeal" followed by your explanation. An AI will review your case and may overturn the ban if it was a mistake.' }
      )
      .setColor(0xFF0000)
      .setTimestamp();
    
    await member.send({ embeds: [embed] }).catch(() => {});
    await member.ban({ reason: `[AUTO] ${reason}`, deleteMessageSeconds: 86400 }).catch(console.error);
    
    await this.logAction(member.id, guild.id, 'ban', reason, confidence, true);
    await this.logToMods(guild, 'ban', member, reason, null, confidence);
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // AUTO-INVESTIGATION SYSTEM
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  investigationQueue = [];
  
  queueInvestigation(userId, guildId, reason) {
    // Don't duplicate
    if (this.investigationQueue.some(i => i.userId === userId && i.guildId === guildId)) return;
    
    this.investigationQueue.push({ userId, guildId, reason, queued: Date.now() });
  }

  async processInvestigationQueue() {
    if (this.investigationQueue.length === 0) return;
    
    // Process up to 3 at a time
    const batch = this.investigationQueue.splice(0, 3);
    
    for (const item of batch) {
      await this.runInvestigation(item.userId, item.guildId, item.reason);
    }
  }

  async runInvestigation(userId, guildId, triggerReason) {
    try {
      // Mark as under investigation
      await this.pool.query(`
        UPDATE sentinel_profiles SET under_investigation = TRUE, last_investigation = NOW()
        WHERE user_id = $1 AND guild_id = $2
      `, [userId, guildId]);
      
      // Gather evidence
      const [messages, profile, actions] = await Promise.all([
        this.pool.query(`
          SELECT content, toxicity, deleted, flagged, flag_reason, created_at 
          FROM sentinel_messages 
          WHERE user_id = $1 AND guild_id = $2 
          ORDER BY created_at DESC LIMIT 50
        `, [userId, guildId]),
        this.getProfile(userId, guildId),
        this.pool.query(`
          SELECT action, reason, created_at FROM sentinel_actions 
          WHERE user_id = $1 AND guild_id = $2 
          ORDER BY created_at DESC LIMIT 20
        `, [userId, guildId])
      ]);
      
      // AI Analysis
      const aiResponse = await this.anthropic.messages.create({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 800,
        messages: [{
          role: 'user',
          content: `You are an autonomous moderation AI. Analyze this user and determine their threat level.

INVESTIGATION TRIGGER: ${triggerReason}

USER PROFILE:
- Trust Score: ${profile.trust_score}/100
- Risk Score: ${profile.risk_score}/100
- Toxicity Score: ${profile.toxicity_score}/100
- Warnings: ${profile.warnings_received}
- Mutes: ${profile.mutes_received}
- Kicks: ${profile.kicks_received}
- Bans: ${profile.bans_received}

RECENT MESSAGES (newest first):
${messages.rows.slice(0, 20).map(m => {
  let line = `"${m.content?.slice(0, 100) || '[empty]'}"`;
  if (m.deleted) line += ' [DELETED]';
  if (m.flagged) line += ` [FLAGGED: ${m.flag_reason}]`;
  if (m.toxicity > 0.5) line += ` [TOXIC: ${(m.toxicity * 100).toFixed(0)}%]`;
  return line;
}).join('\n')}

PAST ACTIONS:
${actions.rows.map(a => `- ${a.action}: ${a.reason}`).join('\n') || 'None'}

Provide your analysis:
1. THREAT_LEVEL: [none/low/medium/high/critical]
2. KEY_CONCERNS: [2-3 bullet points]
3. RECOMMENDED_ACTION: [none/watch/warn/mute/kick/ban]
4. REASONING: [Brief explanation]
5. CONFIDENCE: [0.0-1.0]`
        }]
      });
      
      const analysis = aiResponse.content[0].text;
      
      // Parse results
      const threatMatch = analysis.match(/THREAT_LEVEL:\s*(\w+)/i);
      const actionMatch = analysis.match(/RECOMMENDED_ACTION:\s*(\w+)/i);
      const confidenceMatch = analysis.match(/CONFIDENCE:\s*([\d.]+)/i);
      
      const threatLevel = threatMatch ? threatMatch[1].toLowerCase() : 'low';
      const recommendedAction = actionMatch ? actionMatch[1].toLowerCase() : 'none';
      const confidence = confidenceMatch ? parseFloat(confidenceMatch[1]) : 0.7;
      
      // Save investigation
      await this.pool.query(`
        INSERT INTO sentinel_investigations (user_id, guild_id, trigger_reason, evidence, ai_analysis, risk_assessment, action_taken)
        VALUES ($1, $2, $3, $4, $5, $6, $7)
      `, [userId, guildId, triggerReason, JSON.stringify({ messages: messages.rows.length, actions: actions.rows.length }), analysis, threatLevel, recommendedAction]);
      
      // Update profile
      await this.pool.query(`
        UPDATE sentinel_profiles 
        SET under_investigation = FALSE, status = $3
        WHERE user_id = $1 AND guild_id = $2
      `, [userId, guildId, threatLevel]);
      
      // Take action if needed (high confidence only)
      if (confidence >= 0.75 && recommendedAction !== 'none' && recommendedAction !== 'watch') {
        const guild = this.client.guilds.cache.get(guildId);
        if (guild) {
          const member = await guild.members.fetch(userId).catch(() => null);
          if (member) {
            const reason = `Auto-investigation: ${threatLevel} threat level`;
            
            switch (recommendedAction) {
              case 'warn':
                await this.executeWarning(member, guild, reason);
                break;
              case 'mute':
                await this.executeMute(member, guild, reason, 60, confidence);
                break;
              case 'kick':
                await this.executeKick(member, guild, reason, confidence);
                break;
              case 'ban':
                await this.executeBan(member, guild, reason, confidence);
                break;
            }
          }
        }
      }
      
      // Alert mods for high/critical
      if (threatLevel === 'high' || threatLevel === 'critical') {
        const guild = this.client.guilds.cache.get(guildId);
        if (guild) {
          await this.alertMods(guild, userId, threatLevel, analysis);
        }
      }
      
    } catch (e) {
      console.error('Investigation error:', e);
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // APPEAL PROCESSING
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  async processAppeal(user, appealMessage) {
    const userId = user.id;
    const appealId = `APL-${Date.now().toString(36).toUpperCase()}`;
    
    // Find what guild they were banned from
    let targetGuild = null;
    let originalAction = null;
    
    for (const [guildId, guild] of this.client.guilds.cache) {
      const ban = await guild.bans.fetch(userId).catch(() => null);
      if (ban) {
        targetGuild = guild;
        originalAction = 'ban';
        break;
      }
    }
    
    if (!targetGuild) {
      return {
        success: false,
        message: "I couldn't find any active bans for your account."
      };
    }
    
    // Get their history
    const [profile, actions, messages] = await Promise.all([
      this.getProfile(userId, targetGuild.id),
      this.pool.query(`SELECT * FROM sentinel_actions WHERE user_id = $1 AND guild_id = $2 ORDER BY created_at DESC LIMIT 10`, [userId, targetGuild.id]),
      this.pool.query(`SELECT content, toxicity, flagged FROM sentinel_messages WHERE user_id = $1 AND guild_id = $2 ORDER BY created_at DESC LIMIT 20`, [userId, targetGuild.id])
    ]);
    
    // AI Review
    const aiResponse = await this.anthropic.messages.create({
      model: 'claude-sonnet-4-20250514',
      max_tokens: 500,
      messages: [{
        role: 'user',
        content: `You are reviewing an appeal. Be fair but firm.

APPEAL MESSAGE:
"${appealMessage}"

USER HISTORY:
- Warnings: ${profile.warnings_received}
- Mutes: ${profile.mutes_received}
- Kicks: ${profile.kicks_received}
- Bans: ${profile.bans_received}
- Risk Score: ${profile.risk_score}/100

PAST ACTIONS:
${actions.rows.map(a => `- ${a.action}: ${a.reason}`).join('\n')}

RECENT MESSAGES (before ban):
${messages.rows.slice(0, 10).map(m => `- "${m.content?.slice(0, 50)}" ${m.toxicity > 0.5 ? '[TOXIC]' : ''}`).join('\n')}

DECISION CRITERIA:
- APPROVE if: First major offense, shows genuine remorse, evidence of misunderstanding
- DENY if: Pattern of violations, severe offense (scam/threats), no accountability

Respond with:
DECISION: [approve/deny]
CONFIDENCE: [0.0-1.0]
REASONING: [2-3 sentences explaining to the user]`
      }]
    });
    
    const review = aiResponse.content[0].text;
    const decisionMatch = review.match(/DECISION:\s*(\w+)/i);
    const confidenceMatch = review.match(/CONFIDENCE:\s*([\d.]+)/i);
    const reasoningMatch = review.match(/REASONING:\s*(.+)/is);
    
    const decision = decisionMatch ? decisionMatch[1].toLowerCase() : 'deny';
    const confidence = confidenceMatch ? parseFloat(confidenceMatch[1]) : 0.7;
    const reasoning = reasoningMatch ? reasoningMatch[1].trim() : 'Decision based on available evidence.';
    
    // Save appeal
    await this.pool.query(`
      INSERT INTO sentinel_appeals (appeal_id, user_id, guild_id, original_action, user_message, ai_review, decision, decision_reason)
      VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
    `, [appealId, userId, targetGuild.id, originalAction, appealMessage, review, decision, reasoning]);
    
    // Execute decision
    if (decision === 'approve') {
      await targetGuild.members.unban(userId, `Appeal approved: ${appealId}`).catch(console.error);
      
      // Reset their risk score
      await this.pool.query(`
        UPDATE sentinel_profiles SET risk_score = 30, is_threat = FALSE, bans_received = GREATEST(0, bans_received - 1)
        WHERE user_id = $1 AND guild_id = $2
      `, [userId, targetGuild.id]);
      
      // Alert mods
      await this.logToMods(targetGuild, 'appeal-approved', { id: userId, user: { tag: user.tag } }, `Appeal ${appealId} approved`, null, confidence);
    } else {
      await this.logToMods(targetGuild, 'appeal-denied', { id: userId, user: { tag: user.tag } }, `Appeal ${appealId} denied`, null, confidence);
    }
    
    return {
      success: true,
      decision,
      reasoning,
      appealId
    };
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // ANOMALY DETECTION - Runs every 30 seconds
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  async runAnomalyDetection() {
    for (const [guildId, guild] of this.client.guilds.cache) {
      try {
        // Check for message spikes
        const spikes = await this.pool.query(`
          SELECT user_id, COUNT(*) as count
          FROM sentinel_messages
          WHERE guild_id = $1 AND created_at > NOW() - INTERVAL '2 minutes'
          GROUP BY user_id
          HAVING COUNT(*) > 15
        `, [guildId]);
        
        for (const row of spikes.rows) {
          if (!this.activeThreats.has(row.user_id)) {
            this.activeThreats.add(row.user_id);
            this.queueInvestigation(row.user_id, guildId, `Activity spike: ${row.count} messages in 2 minutes`);
          }
        }
        
        // Check for high deletion rates
        const deleters = await this.pool.query(`
          SELECT user_id,
            COUNT(*) FILTER (WHERE deleted) as deleted,
            COUNT(*) as total
          FROM sentinel_messages
          WHERE guild_id = $1 AND created_at > NOW() - INTERVAL '1 hour'
          GROUP BY user_id
          HAVING COUNT(*) > 10 AND COUNT(*) FILTER (WHERE deleted)::float / COUNT(*) > 0.3
        `, [guildId]);
        
        for (const row of deleters.rows) {
          this.queueInvestigation(row.user_id, guildId, `High deletion rate: ${Math.round(row.deleted / row.total * 100)}%`);
        }
        
      } catch (e) {
        // Continue
      }
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // RAID DETECTION
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  async checkNewMember(member) {
    const now = Date.now();
    const guildId = member.guild.id;
    
    // Track joins
    this.recentJoins.push({ userId: member.id, userId: member.id, guildId, time: now, accountAge: now - member.user.createdTimestamp });
    this.recentJoins = this.recentJoins.filter(j => now - j.time < 60000);
    
    const guildJoins = this.recentJoins.filter(j => j.guildId === guildId);
    
    // Raid detection
    if (guildJoins.length >= 10) {
      await this.alertMods(member.guild, null, 'RAID', `ğŸš¨ RAID DETECTED: ${guildJoins.length} accounts joined in the last minute!`);
      return { isRaid: true };
    }
    
    // New account detection
    const accountAgeHours = (now - member.user.createdTimestamp) / 3600000;
    if (accountAgeHours < 24) {
      // Create profile with elevated risk
      await this.pool.query(`
        INSERT INTO sentinel_profiles (user_id, guild_id, risk_score, status)
        VALUES ($1, $2, 30, 'new_account')
        ON CONFLICT (user_id, guild_id) DO UPDATE SET status = 'new_account'
      `, [member.id, guildId]);
      
      if (accountAgeHours < 2) {
        await this.alertMods(member.guild, member.id, 'new_account', `âš ï¸ Very new account joined: <@${member.id}> (${accountAgeHours.toFixed(1)} hours old)`);
      }
      
      return { isNewAccount: true, hours: accountAgeHours };
    }
    
    return {};
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // DAILY REPORTS
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  scheduleDailyReport() {
    const scheduleNext = () => {
      const now = new Date();
      const next = new Date(now);
      next.setUTCHours(6, 0, 0, 0);
      if (now >= next) next.setDate(next.getDate() + 1);
      
      setTimeout(async () => {
        await this.sendDailyReports();
        scheduleNext();
      }, next.getTime() - now.getTime());
    };
    
    scheduleNext();
  }

  async sendDailyReports() {
    for (const [guildId, guild] of this.client.guilds.cache) {
      try {
        const yesterday = new Date();
        yesterday.setDate(yesterday.getDate() - 1);
        const dateStr = yesterday.toISOString().split('T')[0];
        
        // Gather stats
        const messages = await this.pool.query(`
          SELECT COUNT(*) as total, COUNT(*) FILTER (WHERE deleted) as deleted
          FROM sentinel_messages WHERE guild_id = $1 AND created_at::date = $2
        `, [guildId, dateStr]);
        
        const actions = await this.pool.query(`
          SELECT action, COUNT(*) as count
          FROM sentinel_actions WHERE guild_id = $1 AND created_at::date = $2
          GROUP BY action
        `, [guildId, dateStr]);
        
        const highRisk = await this.pool.query(`
          SELECT user_id, risk_score, status FROM sentinel_profiles
          WHERE guild_id = $1 AND risk_score > 50
          ORDER BY risk_score DESC LIMIT 10
        `, [guildId]);
        
        const investigations = await this.pool.query(`
          SELECT COUNT(*) as count FROM sentinel_investigations
          WHERE guild_id = $1 AND created_at::date = $2
        `, [guildId, dateStr]);
        
        const appeals = await this.pool.query(`
          SELECT decision, COUNT(*) as count FROM sentinel_appeals
          WHERE guild_id = $1 AND created_at::date = $2
          GROUP BY decision
        `, [guildId, dateStr]);
        
        // Build stats
        const stats = {
          messages: parseInt(messages.rows[0]?.total) || 0,
          deletions: parseInt(messages.rows[0]?.deleted) || 0,
          actions: {},
          investigations: parseInt(investigations.rows[0]?.count) || 0,
          appeals: { approved: 0, denied: 0 }
        };
        
        for (const row of actions.rows) {
          stats.actions[row.action] = parseInt(row.count);
        }
        
        for (const row of appeals.rows) {
          stats.appeals[row.decision] = parseInt(row.count);
        }
        
        // AI Summary
        let aiSummary = '';
        try {
          const response = await this.anthropic.messages.create({
            model: 'claude-sonnet-4-20250514',
            max_tokens: 200,
            messages: [{
              role: 'user',
              content: `Write a brief 2-3 sentence daily moderation summary:
- Messages: ${stats.messages} (${stats.deletions} deleted)
- Warnings: ${stats.actions.warning || 0}
- Mutes: ${stats.actions.mute || 0}
- Kicks: ${stats.actions.kick || 0}
- Bans: ${stats.actions.ban || 0}
- Investigations: ${stats.investigations}
- Appeals: ${stats.appeals.approved} approved, ${stats.appeals.denied} denied
- High-risk users: ${highRisk.rows.length}

Be concise. Note anything unusual or concerning.`
            }]
          });
          aiSummary = response.content[0].text;
        } catch (e) {
          aiSummary = 'Summary generation unavailable.';
        }
        
        // Save report
        await this.pool.query(`
          INSERT INTO sentinel_reports (guild_id, report_date, stats, high_risk_users, ai_summary)
          VALUES ($1, $2, $3, $4, $5)
          ON CONFLICT (guild_id, report_date) DO NOTHING
        `, [guildId, dateStr, JSON.stringify(stats), JSON.stringify(highRisk.rows), aiSummary]);
        
        // Send to mod channel
        const modChannel = guild.channels.cache.find(c => 
          c.name.includes('mod-log') || c.name.includes('staff') || c.name.includes('admin')
        );
        
        if (modChannel) {
          const embed = new EmbedBuilder()
            .setTitle(`ğŸ“Š Daily Sentinel Report - ${dateStr}`)
            .setDescription(aiSummary)
            .addFields(
              { name: 'ğŸ’¬ Messages', value: `${stats.messages.toLocaleString()} total\n${stats.deletions} deleted`, inline: true },
              { name: 'ğŸ¤– Actions', value: `âš ï¸ ${stats.actions.warning || 0} warns\nğŸ”‡ ${stats.actions.mute || 0} mutes\nğŸ‘¢ ${stats.actions.kick || 0} kicks\nğŸ”¨ ${stats.actions.ban || 0} bans`, inline: true },
              { name: 'ğŸ” Investigations', value: `${stats.investigations} auto-investigations\n${stats.appeals.approved + stats.appeals.denied} appeals processed`, inline: true }
            )
            .setColor(0x5865F2)
            .setFooter({ text: 'ğŸ›¡ï¸ Sentinel - Autonomous Protection' })
            .setTimestamp();
          
          if (highRisk.rows.length > 0) {
            embed.addFields({
              name: 'âš ï¸ High-Risk Users',
              value: highRisk.rows.slice(0, 5).map(u => `<@${u.user_id}> (Risk: ${u.risk_score})`).join('\n'),
              inline: false
            });
          }
          
          await modChannel.send({ embeds: [embed] });
        }
        
      } catch (e) {
        console.error(`Report error for ${guildId}:`, e);
      }
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // RISK SCORE UPDATES - Runs every 2 minutes
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  async updateAllRiskScores() {
    try {
      // Decay risk scores slowly for inactive users
      await this.pool.query(`
        UPDATE sentinel_profiles
        SET risk_score = GREATEST(0, risk_score - 1)
        WHERE last_active < NOW() - INTERVAL '1 hour' AND risk_score > 0
      `);
      
      // Increase trust for good behavior
      await this.pool.query(`
        UPDATE sentinel_profiles
        SET trust_score = LEAST(100, trust_score + 1)
        WHERE last_active > NOW() - INTERVAL '24 hours'
          AND warnings_received = 0
          AND mutes_received = 0
          AND toxicity_score < 20
      `);
      
    } catch (e) {
      // Continue
    }
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // UTILITIES
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  async getProfile(userId, guildId) {
    const result = await this.pool.query(`
      SELECT * FROM sentinel_profiles WHERE user_id = $1 AND guild_id = $2
    `, [userId, guildId]);
    
    if (result.rows.length === 0) {
      await this.pool.query(`
        INSERT INTO sentinel_profiles (user_id, guild_id) VALUES ($1, $2)
        ON CONFLICT DO NOTHING
      `, [userId, guildId]);
      return { trust_score: 50, risk_score: 0, warnings_received: 0, mutes_received: 0, kicks_received: 0, bans_received: 0 };
    }
    
    return result.rows[0];
  }

  async updateProfile(userId, guildId, analysis) {
    await this.pool.query(`
      INSERT INTO sentinel_profiles (user_id, guild_id, total_messages, last_active)
      VALUES ($1, $2, 1, NOW())
      ON CONFLICT (user_id, guild_id) DO UPDATE SET
        total_messages = sentinel_profiles.total_messages + 1,
        messages_today = sentinel_profiles.messages_today + 1,
        last_active = NOW()
    `, [userId, guildId]);
    
    // Update toxicity if flagged
    if (analysis.toxicity > 0.3) {
      await this.pool.query(`
        UPDATE sentinel_profiles
        SET toxicity_score = LEAST(100, toxicity_score + $3)
        WHERE user_id = $1 AND guild_id = $2
      `, [userId, guildId, Math.round(analysis.toxicity * 10)]);
    }
  }

  async logMessage(message, analysis) {
    await this.pool.query(`
      INSERT INTO sentinel_messages (message_id, user_id, guild_id, channel_id, content, sentiment, toxicity, flagged, flag_reason)
      VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
    `, [
      message.id,
      message.author.id,
      message.guild.id,
      message.channel.id,
      message.content.slice(0, 2000),
      analysis.sentiment,
      analysis.toxicity,
      analysis.flags.length > 0,
      analysis.flags.join(', ') || null
    ]);
  }

  async logAction(userId, guildId, action, reason, confidence, dmSent, dmContent = null) {
    await this.pool.query(`
      INSERT INTO sentinel_actions (user_id, guild_id, action, reason, confidence, dm_sent, dm_content)
      VALUES ($1, $2, $3, $4, $5, $6, $7)
    `, [userId, guildId, action, reason, confidence, dmSent, dmContent]);
  }

  async logToMods(guild, action, member, reason, extra = null, confidence = null) {
    const modChannel = guild.channels.cache.find(c => 
      c.name.includes('mod-log') || c.name.includes('mod-actions')
    );
    if (!modChannel) return;
    
    const emojis = { 
      'warning': 'âš ï¸', 'mute': 'ğŸ”‡', 'kick': 'ğŸ‘¢', 'ban': 'ğŸ”¨',
      'appeal-approved': 'âœ…', 'appeal-denied': 'âŒ',
      'investigation': 'ğŸ”', 'new_account': 'ğŸ‘¶', 'RAID': 'ğŸš¨'
    };
    const colors = {
      'warning': 0xFFAA00, 'mute': 0xFF8C00, 'kick': 0xFF4500, 'ban': 0xFF0000,
      'appeal-approved': 0x00FF00, 'appeal-denied': 0xFF6B6B,
      'investigation': 0x5865F2, 'new_account': 0xFFAA00, 'RAID': 0xFF0000
    };
    
    const embed = new EmbedBuilder()
      .setDescription(`${emojis[action] || 'ğŸ¤–'} **${action.toUpperCase()}**\n\n${typeof member === 'string' ? member : `**User:** <@${member.id}>`}\n**Reason:** ${reason}`)
      .setColor(colors[action] || 0x5865F2)
      .setFooter({ text: confidence ? `Confidence: ${Math.round(confidence * 100)}% â€¢ Sentinel` : 'Sentinel - Autonomous' })
      .setTimestamp();
    
    if (extra) embed.addFields({ name: 'Details', value: extra, inline: true });
    
    await modChannel.send({ embeds: [embed] }).catch(() => {});
  }

  async alertMods(guild, userId, level, message) {
    const modChannel = guild.channels.cache.find(c => 
      c.name.includes('mod-log') || c.name.includes('alerts') || c.name.includes('staff')
    );
    if (!modChannel) return;
    
    const embed = new EmbedBuilder()
      .setTitle(`ğŸš¨ ALERT: ${level.toUpperCase()}`)
      .setDescription(userId ? `**User:** <@${userId}>\n\n${message}` : message)
      .setColor(level === 'critical' || level === 'RAID' ? 0xFF0000 : 0xFF8C00)
      .setTimestamp();
    
    await modChannel.send({ embeds: [embed] }).catch(() => {});
  }

  async cleanup() {
    // Reset daily message counts at midnight
    const hour = new Date().getUTCHours();
    if (hour === 0) {
      await this.pool.query(`UPDATE sentinel_profiles SET messages_today = 0`);
    }
    
    // Clean old message logs (keep 30 days)
    await this.pool.query(`DELETE FROM sentinel_messages WHERE created_at < NOW() - INTERVAL '30 days'`);
    
    // Clear active threats
    this.activeThreats.clear();
  }

  // Track message deletions
  async trackDeletion(message) {
    await this.pool.query(`
      UPDATE sentinel_messages SET deleted = TRUE WHERE message_id = $1
    `, [message.id]);
    
    await this.pool.query(`
      UPDATE sentinel_profiles 
      SET total_deletions = total_deletions + 1
      WHERE user_id = $1 AND guild_id = $2
    `, [message.author?.id, message.guild?.id]);
  }
}

module.exports = SentinelSystem;
